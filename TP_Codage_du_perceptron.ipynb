{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurone formel\n",
    "### Modules necessaires :\n",
    "- NUMPY 1.16.3\n",
    "- MATPLOTLIB : 3.0.3\n",
    "- TENSORFLOW : 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp,array,random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codons notre premier neurone formel \"From Scratch\"\n",
    "\n",
    "Voici un exemple de programme de neurone formel pour bien comprendre toute la mécanique de l'apprentissage à travers un exemple concret.\n",
    "\n",
    "## Les données d'apprentissage\n",
    "\n",
    "La première chose nous allons créer nos données d'apprentissage et définir le taux d'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "#    OBSERVATIONS ET PREDICTIONS\n",
    "#-------------------------------------\n",
    "\n",
    "observations_entrees = array([\n",
    "                              [1, 0],\n",
    "                              [1, 1],\n",
    "                              [0, 1],\n",
    "                              [0, 0]\n",
    "                              ])\n",
    "\n",
    "predictions = array([[0],[1], [0],[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des poids\n",
    "\n",
    "On génère les poids de façon aléatoire, dans l'intervalle de valeur [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#        PARAMETRAGE DU PERCEPTRON\n",
    "#--------------------------------------\n",
    "\n",
    "#Génération des poids dans l'interval [-1;1]\n",
    "\n",
    "random.seed(1)\n",
    "borneMin = -1\n",
    "borneMax = 1\n",
    "\n",
    "w11 = (borneMax-borneMin) * random.random() + borneMin\n",
    "w21 = (borneMax-borneMin) * random.random() + borneMin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Le biais qui aura pour valeur 1 et le poids sera égal à 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le biais\n",
    "biais = 1\n",
    "wb = 0\n",
    "\n",
    "#Stockage des poids initiaux, uniquement pour affichage à la fin de l'apprentissage\n",
    "poids = [w11,w21,wb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taux d'apprentissage\n",
    "txApprentissage = 0.1\n",
    "\n",
    "#Nombres d'epoques\n",
    "#epochs = 300000\n",
    "epochs = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codage de fonctions utiles\n",
    "\n",
    "Le code ci-dessous représente les différentes fonctions dont nous aurons besoin à savoir:\n",
    "\n",
    "- Le calcul de la somme pondérée\n",
    "- Le calcul de la fonction d'activation de type sigmoïde \n",
    "- Le calcul de l'erreur linéaire\n",
    "- Le calcul du gradient\n",
    "- Le calcul de la valeur d'ajustement du poids\n",
    "- Le calcul de la nouvelle valeur du poids\n",
    "- Le calcul de la fonction d'erreur moyenne quadratique (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#       FONCTIONS UTILES\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "#This function calculate the somme ponderee of the neural network\n",
    "def somme_ponderee(X1,W11,X2,W21,B,WB):\n",
    "    return B*WB+W11*X1+W21*X2\n",
    "\n",
    "#This function activate the somme ponderee with the sigmoide. \n",
    "def fonction_activation_sigmoide(valeur_somme_ponderee):\n",
    "    return (1/(1+math.exp(-valeur_somme_ponderee)))\n",
    "\n",
    "#This function activate the somme ponderee with the relu function. \n",
    "def fonction_activation_relu(valeur_somme_ponderee):\n",
    "    if (valeur_somme_ponderee <0):\n",
    "        return 0\n",
    "    else:\n",
    "        return valeur_somme_ponderee\n",
    "\n",
    "#We calcule the difference beetween the real value and the predict value. \n",
    "def erreur_lineaire(valeur_attendue, valeur_predite):\n",
    "    return valeur_attendue-valeur_predite\n",
    "\n",
    "#We calcul the gradient of the value to retro progation the neural network\n",
    "def calcul_gradient(valeur_entree,prediction,erreur):\n",
    "   return -1*erreur*prediction*(1-prediction)*valeur_entree \n",
    "\n",
    "#We calcul the new weight with the reajusted value\n",
    "def calcul_valeur_ajustement(valeur_gradient, taux_apprentissage):\n",
    "    return valeur_gradient*taux_apprentissage\n",
    "\n",
    "#We the new value of adjsutment, we calcul the new weight\n",
    "def calcul_nouveau_poids (valeur_poids, valeur_ajustement):\n",
    "    return valeur_poids*valeur_ajustement\n",
    "\n",
    "#We finally calcul the MSE to show the graĥ of the loss. \n",
    "def calcul_MSE(predictions_realisees, predictions_attendues):\n",
    "    cpt=0\n",
    "    for i in range(len(predictions_attendues)):\n",
    "        cpt+=math.pow(erreur_lineaire(predictions_attendues[i],predictions_realisees[i]),2)\n",
    "    return 1/len(predictions_attendues)*cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#       GRAPHIQUE\n",
    "#--------------------------------------\n",
    "\n",
    "#Change this into a real function\n",
    "Graphique_MSE=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage!\n",
    "\n",
    "Maintenant que nous disposons de tout ce dont nous avons besoin, nous pouvons passer à la phase d'apprentissage.\n",
    "\n",
    "Pour mener à bien cette phase d'apprentissage, nous allons \n",
    "* réaliser plusieurs époques (epoch), c'est-à-dire plusieurs passages complets de l'ensemble des observations contenues dans notre jeu de données à travers notre neurone formel. \n",
    "* réaliser pour chaque observation une prédiction et calculer l'erreur pour ensuite procéder à la mise à jour des poids synaptiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#    APPRENTISSAGE\n",
    "#--------------------------------------\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    print(\"EPOCH (\"+str(epoch)+\"/\"+str(epochs)+\")\")\n",
    "    predictions_realisees_durant_epoch = [];\n",
    "    predictions_attendues = [];\n",
    "    numObservation = 0\n",
    "    for observation in observations_entrees:\n",
    "        #print(\"Numéro Observation: \", numObservation)\n",
    "        #Chargement de la couche d'entrée\n",
    "        x1 = observation[0];\n",
    "        x2 = observation[1];\n",
    "\n",
    "        #Valeur de prédiction attendue\n",
    "        # valeur_attendue =\n",
    "\n",
    "        #Etape 1 : Calcul de la somme ponderee\n",
    "        # valeur_somme_ponderee = \n",
    "\n",
    "\n",
    "        #Etape 2 : Application de la fonction d'activation\n",
    "        # valeur_predite = \n",
    "\n",
    "\n",
    "        #Etape 3 : Calcul de l'erreur\n",
    "        # valeur_erreur = \n",
    "\n",
    "\n",
    "        #Mise à jour du poids 1\n",
    "        #Calcul du gradient de la valeur d'ajustement et du nouveau poids\n",
    "        # gradient_W11 = \n",
    "        # valeur_ajustement_W11 = \n",
    "        # w11 = \n",
    "\n",
    "        # Mise à jour du poids 2\n",
    "        # gradient_W21 = \n",
    "        # valeur_ajustement_W21 = \n",
    "        # w21 = \n",
    "\n",
    "\n",
    "        # Mise à jour du poids du biais\n",
    "        # gradient_Wb = \n",
    "        # valeur_ajustement_Wb = \n",
    "        # wb = \n",
    "\n",
    "        ##print(\"     EPOCH (\" + str(epoch) + \"/\" + str(epochs) + \") -  Observation: \" + str(numObservation+1) + \"/\" + str(len(observations_entrees)))\n",
    "\n",
    "        #Stockage de la prediction realisee:\n",
    "        predictions_realisees_durant_epoch.append(valeur_predite)\n",
    "        predictions_attendues.append(predictions[numObservation][0])\n",
    "\n",
    "        #Passage à l'observation suivante\n",
    "        numObservation = numObservation+1\n",
    "\n",
    "    MSE = calcul_MSE(predictions_realisees_durant_epoch, predictions)\n",
    "    Graphique_MSE.append(MSE[0])\n",
    "    ##print(\"MSE : \"+str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après exécution du code, on constate que la fonction d'erreur diminue au fil du temps, ce qui montre que notre neurone formel est bien en train d'apprendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Graphique_MSE)\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mais avons-nous atteint le point de convergence?\n",
    "\n",
    "On voit bien d'après le graphe une diminution de l'erreur puis un léger palier pour ensuite reprendre la descente, mais cela ne nous indique pas si la convergence a été atteinte, on peut juste en déduire qu'avec une fonction d'erreur montrant un taux de 8% et vu l'allure de la courbe, nous pouvons encore espérer de meilleurs résultats.\n",
    "\n",
    "> Essayez de modifier le nombre d'epochs en le passant à 1000000 et à relancer l'apprentissage (attention, cela peut prendre du temps). Cette énorme valeur a volontairement été choisie pour vous montrer que notre algorithme continue toujours à améliorer son apprentissage, mais de façon très minime puisque la courbe de la fonction d'erreur semble se stabiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de prédictions\n",
    "\n",
    "Essayons à présent de réaliser quelques prédictions pour vérifier le bon fonctionnement de notre neurone artificiel.\n",
    "\n",
    "Dans un premier temps, nous allons changer le nombre d'epochs pour le mettre à 3000.\n",
    "\n",
    "Ajoutons quelques lignes qui vont nous permettre de connaître les poids issus de l'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print()\n",
    "print (\"Apprentissage terminé !\")\n",
    "print (\"Poid initiaux: \" )\n",
    "print (\"W11 = \"+str(poids[0]))\n",
    "print (\"W21 = \"+str(poids[1]))\n",
    "print (\"Wb = \"+str(poids[3]))\n",
    "\n",
    "print (\"Poid finaux: \" )\n",
    "print (\"W11 = \"+str(w11))\n",
    "print (\"W21 = \"+str(w21))\n",
    "print (\"Wb = \"+str(wb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis réalisons une prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"--------------------------\")\n",
    "print (\"PREDICTION \")\n",
    "print(\"--------------------------\")\n",
    "x1 = 1\n",
    "x2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etape 1 : Calcul de la somme ponderee\n",
    "valeur_somme_ponderee = somme_ponderee(x1,w11,x2,w21,biais,wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etape 2 : Application de la fonction d'activation\n",
    "valeur_predite = fonction_activation_sigmoide(valeur_somme_ponderee)\n",
    "#valeur_predite = fonction_activation_relu(valeur_somme_ponderee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction du [\" + str(x1) + \",\" + str(x2)  + \"]\")\n",
    "print(\"Prediction = \" + str(valeur_predite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
