{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be5uBRdgbhey"
   },
   "source": [
    "# CNNs avec Keras sur des données de paysage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-diCsctWfSh"
   },
   "source": [
    "## Vérification de l'utilisation de GPU\n",
    "\n",
    "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-S9vf7TtjjMa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW2_sMt8cSP-"
   },
   "source": [
    "## Téléchargement du dataset Landscape depuis un repo git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TZXdRwk2Lq3i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset-landscape'...\n",
      "remote: Enumerating objects: 24310, done.\u001b[K\n",
      "remote: Total 24310 (delta 0), reused 0 (delta 0), pack-reused 24310\u001b[K\n",
      "Receiving objects: 100% (24310/24310), 342.22 MiB | 19.23 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "Checking out files: 100% (24337/24337), done.\n",
      "README.md  README.md~  seg_pred  seg_test  seg_train\n",
      "***\n",
      "total 0\n",
      "drwxr-xr-x 2 ovh ovh 2191 Nov 16 15:10 buildings\n",
      "drwxr-xr-x 2 ovh ovh 2271 Nov 16 15:10 forest\n",
      "drwxr-xr-x 2 ovh ovh 2404 Nov 16 15:10 glacier\n",
      "drwxr-xr-x 2 ovh ovh 2512 Nov 16 15:10 mountain\n",
      "drwxr-xr-x 2 ovh ovh 2274 Nov 16 15:10 sea\n",
      "drwxr-xr-x 2 ovh ovh 2382 Nov 16 15:10 street\n",
      "***\n",
      "total 0\n",
      "drwxr-xr-x 2 ovh ovh 7301 Nov 16 15:10 no_supervision\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nzmonzmp/dataset-landscape.git\n",
    "!ls dataset-landscape\n",
    "print(\"***\")\n",
    "!ls -l dataset-landscape/seg_train\n",
    "print(\"***\")\n",
    "!ls -l dataset-landscape/seg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5hheTPDcdqN"
   },
   "source": [
    "## Import de TensorFlow et des autres librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SvZJ4yH6cNHE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 15:25:07.730778: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-16 15:25:09.224426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /workspace/.miniconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-11-16 15:25:09.224981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /workspace/.miniconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-11-16 15:25:09.225004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import typing\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.utils\n",
    "import sklearn.metrics\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zCSZcuhczAn"
   },
   "source": [
    "## Préparation des données\n",
    "\n",
    "Pour charger nos données, nous allons combiner plusieurs libraires : [OpenCV](https://opencv.org/), [NumPy](https://numpy.org/) et [scikit-learn](https://scikit-learn.org/stable/). Ces librairies seront appelées depuis la fonction `get_images`.\n",
    "\n",
    "Après avoir chargé chaque image, nous allons passer leur canaux en RGB puis les redimensionner à 150x150, enfin, par défaut, nous retournerons un dataset mélangé grâce à [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html).\n",
    "\n",
    "*Complétez la fonction `get_images` qui va chercher les images dans `dir_path` contenant un dossier par classe. Chaque dossier de classe contient l'ensemble des images de cette classe. Il vous faut attribuer le label correct à chaque image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l84GytKmeZM7"
   },
   "outputs": [],
   "source": [
    "label_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "\n",
    "\n",
    "def get_images(dir_path: pathlib.Path, shuffle: bool = True\n",
    "              ) -> typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
    "  images = []\n",
    "  labels = []\n",
    "  file_paths  = []\n",
    "\n",
    "  # On itère sur les sous-dossier de la racine : ils correspondent chacun à une\n",
    "  # classe\n",
    "  for subdir_path in dir_path.iterdir():\n",
    "\n",
    "    # Attribuez le bon label en fonction du nom du dossier \"labels\"\n",
    "    # Votre code ici\n",
    "    label = None\n",
    "\n",
    "    # On ajoute chaque image du label (dossier) courant à notre dataset\n",
    "    for image_path in subdir_path.iterdir():\n",
    "      # Utilisation de OpenCV pour charger l'image\n",
    "      image = cv2.imread(str(image_path))\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      # En entrée d'un CNN, toutes les images doivent faire la même taille\n",
    "      image = cv2.resize(image, (150, 150))\n",
    "      images.append(image)\n",
    "      labels.append(label)\n",
    "      file_paths.append(image_path)\n",
    "\n",
    "  # Création des tableaux numpy que l'on va retourner\n",
    "  images, labels, file_paths = map(numpy.array, [images, labels, file_paths])\n",
    "\n",
    "  # Mélange de ces tableaux\n",
    "  if shuffle:\n",
    "    images, labels, file_paths = sklearn.utils.shuffle(images,\n",
    "                                                       labels,\n",
    "                                                       file_paths)\n",
    "  return images, labels, file_paths\n",
    "\n",
    "\n",
    "# get_images(pathlib.Path(\"dataset-landscape\") / \"seg_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbswqLLSgMzK"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12Co3AuagRdQ"
   },
   "source": [
    "## Appel à `get_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mlWHQMqbgUi_"
   },
   "outputs": [],
   "source": [
    "images, labels, file_paths = get_images(\n",
    "    pathlib.Path(\"dataset-landscape\") / \"seg_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Z9CFPgYahZ-_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme des images : (14034, 150, 150, 3)\n",
      "Forme des labels : (14034,)\n",
      "Forme des chemins : (14034,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForme des labels : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForme des chemins : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_paths\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m seaborn\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDécomptes des différents labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDécompte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/site-packages/seaborn/categorical.py:2942\u001b[0m, in \u001b[0;36mcountplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2940\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2942\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_CountPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2949\u001b[0m plotter\u001b[38;5;241m.\u001b[39mvalue_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/site-packages/seaborn/categorical.py:1532\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_variables(x, y, hue, data, orient,\n\u001b[1;32m   1531\u001b[0m                          order, hue_order, units)\n\u001b[0;32m-> 1532\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_colors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdodge \u001b[38;5;241m=\u001b[39m dodge\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.9/site-packages/seaborn/categorical.py:707\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_colors\u001b[0;34m(self, color, palette, saturation)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Determine the gray color to use for the lines framing the plot\u001b[39;00m\n\u001b[1;32m    706\u001b[0m light_vals \u001b[38;5;241m=\u001b[39m [rgb_to_hls(\u001b[38;5;241m*\u001b[39mc)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m rgb_colors]\n\u001b[0;32m--> 707\u001b[0m lum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlight_vals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m.6\u001b[39m\n\u001b[1;32m    708\u001b[0m gray \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mrgb2hex((lum, lum, lum))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# Assign object attributes\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "print(f\"Forme des images : {images.shape}\")\n",
    "print(f\"Forme des labels : {labels.shape}\")\n",
    "print(f\"Forme des chemins : {file_paths.shape}\")\n",
    "\n",
    "seaborn.countplot(x=labels)\n",
    "plt.title(\"Décomptes des différents labels\")\n",
    "plt.ylabel(\"Décompte\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRP8sepdhh8I"
   },
   "outputs": [],
   "source": [
    "# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n",
    "# la taille de la figure qui est petite par défaut\n",
    "f, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
    "\n",
    "# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n",
    "# même image deux fois)\n",
    "random_indexes = numpy.random.choice(images.shape[0],\n",
    "                                     size=(5, 5),\n",
    "                                     replace=False)\n",
    "\n",
    "for i in range(5):\n",
    "  for j in range(5):\n",
    "    img_index = random_indexes[i, j]\n",
    "    image = images[img_index]\n",
    "    label = label_names[labels[img_index]]\n",
    "\n",
    "    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n",
    "    # ordinateur\n",
    "    ax[i, j].imshow(image)\n",
    "    ax[i, j].set_title(f\"Exemple {img_index} ({label})\")\n",
    "    ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JOKqXxDP5jB"
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Voici un exemple de CNN « minimaliste »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFvhX0LZjZw3"
   },
   "outputs": [],
   "source": [
    "# Initialisation et définition du modéle\n",
    "\n",
    "# Le modèle est un empilement de couches où le flux de données est séquentiel\n",
    "# déclarer et créer un modèle sequentiel \n",
    "# Votre Code ici\n",
    "\n",
    "\n",
    "# Une première couche de 1 convolutions de 3x3 pixels\n",
    "# VOtre code ici\n",
    "\n",
    "# Une couche de max pooling\n",
    "# Votre code ici\n",
    "\n",
    "# Une couche de manipulation des tenseurs : suppression de toutes les dimensions\n",
    "# sauf celle de batch et une autre qui contient toutes les valeurs (flaten)\n",
    "# VOtre code ici\n",
    "\n",
    "# Une couche de sortie dense avec 6 neurones et un softmax comme activation\n",
    "# VOtre code ici\n",
    "\n",
    "# Compilation du modèle avec la définition de la fonction de perte\n",
    "# Votre code ici\n",
    "# Optimizer :  Adam, learning rate = 0.0001\n",
    "# loss : sparse categorical crossentropy\n",
    "# metric : accuracy\n",
    "\n",
    "\n",
    "# Affichage d'un résumé du modèle\n",
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYBPo9koUi7k"
   },
   "source": [
    "## Pouvez-vous expliquer les différents nombres de paramètres ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6jAWFPyP85p"
   },
   "source": [
    "### Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woNSPikeU_xl"
   },
   "source": [
    "## Apprentissage\n",
    "\n",
    "Apprenons ce modèle sur nos données ! Dans un premier temps, nous entraînons sur une seule epoch pour simplement vérifier que notre modèle est opérationnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vg7kkCCiyB_"
   },
   "outputs": [],
   "source": [
    "# Apprentissage du modèle\n",
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffuXmAvTuqF"
   },
   "source": [
    "## Améliorez cette performance\n",
    "\n",
    "Inspirez-vous du modèle précédent en rajoutant des couches, en faisant des couches plus petites ou plus grosses.\n",
    "\n",
    "Visez entre 10 et 20 itérations et mois de 1 minute par itération (pour des raisons évidentes).\n",
    "\n",
    "On peut considérer l'utilisation d'une couche de dropout juste avant la dernière couche dense pour améliorer la régularisation.\n",
    "\n",
    "On peut obtenir une précision supérieure à 70% sur la base de validation en un temps raisonnable.\n",
    "\n",
    "La solution proposée prend $\\approx$ 45 secondes par itération pendant 15 itérations et atteint aux alentour de 85% d'accuracy sur la base de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-j7dwcWUdZx"
   },
   "outputs": [],
   "source": [
    "# Vos améliorations ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGazvkPxP0oX"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bIuRTZYAnWR"
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PsIIXF0hzy5"
   },
   "outputs": [],
   "source": [
    "# Apprentissage du modèle\n",
    "# # Votre code ici\n",
    "\n",
    "# Visualisation des métriques d'entrainement\n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hb_IT9QWeYPh"
   },
   "source": [
    "## Évaluation des performances sur l'ensemble de test\n",
    "\n",
    "Dans le dossier `seg_test` se trouve un ensemble de données qui n'ont jamais été vues durant l'apprentissage.\n",
    "\n",
    "On utilisera la méthode `evaluate(X, y)` du modèle pour évaluer la qualité de nos prédictions sur ce dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJubx-J7i882"
   },
   "outputs": [],
   "source": [
    "test_images,test_labels, test_file_paths = get_images(\n",
    "    pathlib.Path(\"dataset-landscape\") / \"seg_test\")\n",
    "\n",
    "# Evaluation \n",
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYPaPc0lpe0B"
   },
   "source": [
    "## Analyse d'erreur\n",
    "\n",
    "On affiche la matrice de confusion puis on regarde des images mal classées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfOlRq1Ep3KD"
   },
   "outputs": [],
   "source": [
    "def analyze_preds(preds, labels):\n",
    "  confusion_matrix = sklearn.metrics.confusion_matrix(preds,\n",
    "                                                      labels,\n",
    "                                                      normalize=\"true\")\n",
    "  seaborn.heatmap(confusion_matrix,\n",
    "                  cmap=\"rocket_r\",\n",
    "                  xticklabels=label_names,\n",
    "                  yticklabels=label_names)\n",
    "  plt.title(\"Matrice de confusion\")\n",
    "  plt.show()\n",
    "\n",
    "  seaborn.countplot(x=list(map(lambda x: label_names[x], preds)))\n",
    "  plt.title(\"Décomptes des classes prédites\")\n",
    "  plt.ylabel(\"Décompte\")\n",
    "  plt.xlabel(\"Class\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "test_pred = numpy.argmax(model.predict(test_images), axis=-1)\n",
    "analyze_preds(test_pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLUCp97BeUxu"
   },
   "outputs": [],
   "source": [
    "def plot_mistakes(predicted_class: str, true_class: str) -> None:\n",
    "  print(f\"Prédiction : {predicted_class}, classe réelle : {true_class}\")\n",
    "  mistakes = test_images[(test_pred == label_to_index[predicted_class])\n",
    "                         & (test_labels == label_to_index[true_class])]\n",
    "  random_indexes = numpy.random.choice(mistakes.shape[0],\n",
    "                                       size=min(mistakes.shape[0], 25),\n",
    "                                       replace=False)\n",
    "  grid_indexes = itertools.product(range(5), repeat=2)\n",
    "\n",
    "  _, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
    "  for img_index, (i, j) in zip(random_indexes, grid_indexes):\n",
    "    ax[i, j].imshow(mistakes[img_index])\n",
    "    ax[i, j].axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43kc6Wgd9bkC"
   },
   "outputs": [],
   "source": [
    "# Plot les images prédites glacier alors qu'elles ont un label montagne\n",
    "plot_mistakes(\"glacier\", \"mountain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QyUe_6T_vL8"
   },
   "outputs": [],
   "source": [
    "# Plot les images prédites glacier alors qu'elles ont un label mer\n",
    "plot_mistakes(\"glacier\", \"sea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAgJItMSDE2-"
   },
   "outputs": [],
   "source": [
    "# Plot les images prédites bâtiment alors qu'elles ont un label mer\n",
    "plot_mistakes(\"buildings\", \"sea\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1xLFNAWBJxmp0GBcRhmwKfZUbewBDq4hz",
     "timestamp": 1637764472783
    },
    {
     "file_id": "1wS56Bvj0KNGqMHIviwd2Y9uwYnUYkT5b",
     "timestamp": 1570893367950
    },
    {
     "file_id": "14MjAMPKQD3LIncUn2YEHJ3fBq8K2upuq",
     "timestamp": 1558960238747
    }
   ]
  },
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
